# âœ… stt_worker/stt_worker.py : redis audio_queue â†’ Whisper STT â†’ redis text_queue + text_channel + analyzer task í˜¸ì¶œ

import numpy as np
import redis
import whisper
import torch
from celery import Celery
import os

# =============================
# ğŸ¯ í™˜ê²½ ì„¤ì •
# =============================
REDIS_HOST = os.getenv("REDIS_HOST", "redis")  # ë„ì»¤ ì»¨í…Œì´ë„ˆ ì´ë¦„
REDIS_PORT = 6379

# =============================
# ğŸ§ Celery + Redis ì—°ê²°
# =============================
celery = Celery('stt', broker=f'redis://{REDIS_HOST}:{REDIS_PORT}/0')


@celery.task(name="stt.transcribe_audio")  # âœ… task ì´ë¦„ ë°˜ë“œì‹œ ì§€ì •
def transcribe_audio():
    """
    ğŸ§ audio_queueì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ê°€ì ¸ì™€ Whisper STTë¡œ ë³€í™˜ í›„
    â†’ text_queue ì €ì¥
    â†’ text_channelìœ¼ë¡œ ì‹¤ì‹œê°„ STT í…ìŠ¤íŠ¸ broadcast
    â†’ analyzer worker task í˜¸ì¶œ (send_task ë°©ì‹)
    """
    try:
        r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT)
        audio_bytes = r.rpop("audio_queue")
        if not audio_bytes:
            return  # queue ë¹„ì—ˆìœ¼ë©´ ì¢…ë£Œ

        # Whisper ëª¨ë¸ ë¡œë“œ
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model = whisper.load_model("small", device=device)

        # ë°”ì´íŠ¸ â†’ numpy ë°°ì—´ë¡œ ë³µì›
        audio = np.frombuffer(audio_bytes, dtype=np.float32)

        # STT ì‹¤í–‰
        result = model.transcribe(
            audio,
            language="ko",
            fp16=(device == "cuda"),
            temperature=0,
            condition_on_previous_text=False
        )

        # í…ìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        text = result['text']
        r.lpush("text_queue", text.encode("utf-8"))
        print(f"âœ… STT ê²°ê³¼ â†’ {text}")

        # ğŸ¯ ì‹¤ì‹œê°„ broadcast (listenerì—ì„œ ì‹¤ì‹œê°„ í™•ì¸ìš©)
        r.publish("text_channel", text)

        # âœ… analyzer worker task í˜¸ì¶œ (ì»¨í…Œì´ë„ˆ í™˜ê²½ ëŒ€ì‘)
        celery.send_task("analyzer.analyze_text")

    except Exception as e:
        print(f"âŒ STT ì˜¤ë¥˜: {e}")
