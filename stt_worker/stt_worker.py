import os
import numpy as np
from scipy.io.wavfile import write
import whisper as openai_whisper
from celery import Celery
import tempfile

# âœ… ê¸°ë³¸ ì„¤ì •
REDIS_HOST = os.getenv("REDIS_HOST", "redis" if os.getenv("DOCKER") else "localhost")
celery = Celery("stt_worker", broker=f"redis://{REDIS_HOST}:6379/0")

# âœ… Whisper ëª¨ë¸ ë¡œë“œ
model_size = os.getenv("MODEL_SIZE", "tiny")
model_path = os.getenv("MODEL_PATH", "/app/models")
os.makedirs(model_path, exist_ok=True)
model = openai_whisper.load_model(model_size, download_root=model_path)

# âœ… ë©”ëª¨ë¦¬ ë‚´ 4ì´ˆ ëˆ„ì  ë²„í¼ (ë‹¨ì¼ ì‚¬ìš©ì ì „ìš©)
buffer = []

@celery.task(name="stt_worker.transcribe_audio", queue="stt_queue")
def transcribe_audio(audio_bytes):
    global buffer

    print("[STT] ğŸ§ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ ")
    buffer.append(np.frombuffer(audio_bytes, dtype=np.int16))

    if len(buffer) < 4:
        print(f"[STT] â³ ëˆ„ì  {len(buffer)}/4...")
        return

    # âœ… 4ì´ˆ ëˆ„ì  ì™„ë£Œ â†’ Whisper ë¶„ì„
    combined = np.concatenate(buffer[:8])  # ìµœëŒ€ 4ì´ˆê¹Œì§€ë§Œ ìë¦„

    with tempfile.NamedTemporaryFile(suffix=".wav") as tmpfile:
        write(tmpfile.name, 16000, combined.astype(np.int16))
        result = model.transcribe(tmpfile.name, language="ko", fp16=False)

    text = result.get("text", "").strip()
    print(f"[STT] ğŸ™ï¸ Whisper STT ê²°ê³¼: {text}")

    if not text:
        print("[STT] âš ï¸ ê³µë°± í…ìŠ¤íŠ¸ â†’ ë¶„ì„ ìƒëµ")
        buffer.clear()
        return "[STT] âš ï¸ ìƒëµë¨"

    # âœ… ê°ì • ë¶„ì„ê¸°ë¡œ ì „ë‹¬
    celery.send_task(
        "analyzer_worker.analyzer_text",
        args=[text],
        queue="analyzer_queue"
    )
    print("[STT] âœ… analyzer_worker í˜¸ì¶œ ì™„ë£Œ")

    # âœ… ë²„í¼ ì´ˆê¸°í™”
    buffer.clear()