# ========================
# ğŸ™ï¸ Whisper Text Analyzer - STT Worker ì„œë¹„ìŠ¤
# ğŸ™ï¸ audio_queue â†’ Whisper STT â†’ text_queue + text_channel
# ========================

import numpy as np
import redis
import whisper
import torch
from celery import Celery
import os

# ========================
# ğŸ¯ Redis + Celery ë¸Œë¡œì»¤ ì„¤ì •
# ========================

REDIS_HOST = os.getenv("REDIS_HOST", "redis" if os.getenv("DOCKER") else "localhost")
REDIS_PORT = 6379
BROKER_URL = f"redis://{REDIS_HOST}:{REDIS_PORT}/0"

# Celery ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë¸Œë¡œì»¤=Redis)
celery = Celery('stt', broker=BROKER_URL)

# Redis í´ë¼ì´ì–¸íŠ¸ (Celeryì™€ ë™ì¼ ë¸Œë¡œì»¤ ì‚¬ìš© â†’ mismatch ë°©ì§€)
r = redis.Redis.from_url(BROKER_URL)

print(f"âœ… stt_worker ì—°ê²° Redis: {BROKER_URL}")

# ========================
# ğŸ¯ Whisper ëª¨ë¸ ì„¤ì •
# ========================

MODEL_SIZE = "small"  # small: ë¹ ë¥´ê³  ì ì ˆí•œ ì •í™•ë„ / medium, large ê°€ëŠ¥
model_instance = None  # ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ 1íšŒë§Œ ë¡œë“œ

def get_model():
    """
    Whisper ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜ (ìµœì´ˆ 1íšŒë§Œ ë¡œë“œ)
    """
    global model_instance
    if model_instance is None:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ¯ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘... (device: {device})")
        model_instance = whisper.load_model(MODEL_SIZE, device=device)
    return model_instance

# ========================
# ğŸ¯ Celery Task ì •ì˜
# ========================

@celery.task(name="stt.transcribe_audio")
def transcribe_audio():
    """
    audio_queue â†’ STT â†’ text_queue + text_channelë¡œ í…ìŠ¤íŠ¸ ì „ì†¡
    """
    try:
        # Redis audio_queueì—ì„œ ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ 
        audio_bytes = r.rpop("audio_queue")
        if not audio_bytes:
            print("âš ï¸ stt_worker: audio_queue ë¹„ì–´ìˆìŒ â†’ ëŒ€ê¸°")
            return

        print("ğŸ™ï¸ stt_worker: audio_queue ë°ì´í„° ìˆ˜ì‹  â†’ STT ì‹œì‘")

        # numpy ë°°ì—´ë¡œ ë³€í™˜
        audio = np.frombuffer(audio_bytes, dtype=np.float32)

        # Whisper STT ìˆ˜í–‰
        result = get_model().transcribe(
            audio,
            language="ko",  # í•œêµ­ì–´ ê³ ì •
            fp16=(torch.cuda.is_available()),
            temperature=0,
            condition_on_previous_text=False
        )

        text = result['text']

        # STT ê²°ê³¼ë¥¼ Redisë¡œ ì „ì†¡
        r.lpush("text_queue", text.encode("utf-8"))
        r.publish("text_channel", text)

        print(f"âœ… [STT ì™„ë£Œ] í…ìŠ¤íŠ¸: {text}")

    except Exception as e:
        print(f"âŒ STT ì˜¤ë¥˜: {e}")
